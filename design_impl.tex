\section{PPF Implementation Using SPP}
\label{Impl}

This section describes our implementation of PPF and the range of
features that are used by the perceptron for correlating the
prefetches. For a practical implementation, we have used SPP as the
base engine prefetcher.

\subsection{Changes Made to SPP}
\label{Impl-Changes}
To modify the SPP design to suit our scheme, the following changes were made:\\
%
\textbf{Original Thresholds Discarded:} In PPF, the perceptron sum is used to
decide whether to prefetch or not, and the fill-level in case of prefetch.
Thus, the confidence thresholds -- T\textsubscript{f} and T\textsubscript{p}
are no longer needed. \\
% djimenez: keeping comments on every line here so it doesn't screw up my
%"roll-your-own" itemized list. don't put in any newlines.
%
%
% EB: Can this point be removed?
% djimenez: I think this would be necessary to reproduce our results so leave it in. 
% EB: It's ultimately a check to avoid SPP's internal segfault. Won't have a real impact.
%
%\item \textbf{Looking at L2 MSHR Queue while prefetching}\newline The
%  original SPP does not consider the slots available in the L2 MSHR
%  queue.  It has the assumption that at no time can the number of
%  suggested prefetches exceed the capacity of the queue.  While it was
%  not described in the paper, the internal confidence mechanism makes
%  sure that the above assumption was maintained.  In PPF, since there
%  cannot be an assumption on the degree of aggressiveness of the
%  underlying prefetcher, we explicitly check that at no point should
%  the number of suggested prefetches exceed the L2 MSHR queue. \pg{is
%    this a big deal?  Seems like a detail}
%
\textbf{Enhanced Prefetch Table:} The prefetch table introduced in the
original SPP keeps track of up to 1024 L2 cache prefetch suggestions. For
PPF, the prefetch table is modified to store the features used for perceptron
indexing.. This metadata is needed to retrieve the values of the features to
train the perceptron at a later stage in time. The prefetch table mentioned
above keeps track of the prefetches that actually happened in the L2 Cache.
We introduce the reject table to keep a track of the prefetches that were
suggested by the base SPP engine but were rejected by PPF. In case it is
detected that a future demand fetch could have used this rejected prefetch,
the perceptron weights are updated to reflect that misprediction. 

\subsection{Features used by Perceptron}
\label{Impl-Features}
Here we discuss the various features that correlate the prefetching
decision with the program behavior. All the features we used can be 
derived from the information available in the L2 Cache access stream.
Our feature selection involved searching over a large space of 
relevant perceptron features. Using the statistical methodology 
outlined in Section~\ref{Method-Features}, we pruned the feature 
set to a minimal yet relevant set of features. \\ \\
% \pg{again you want to get at why
% these were chosen. Also mention that you searched over a large
% space of possible features and these were the best.}
%
% [EB] Tried addressing. Does it look redundant when read after 'Feature Selection'
% bullet from the previous section?
%
\textbf{Base Address}: The base address of the demand access that triggers the
prefetch corresponds to a stream of future accesses that SPP and the PPF have
seen before. Therefore, PPF will correlate the past behavior of this address
to the confidence of a prefetch. \\
%
\textbf{Cache Line} and \textbf{Page Address}: These two separate features are
derived from the base address that triggered the prefetch, as follows:
base\_addr >> LOG2\_BLOCK \_SIZE and base\_addr >> LOG2\_PAGE\_SIZE
respectively. The idea behind using three different shifted versions of the
same feature is that it allows us to look into a wider range of bits than with
a single version. It also helps give more importance to the overlapping bits
and lesser importance to most and least significance bits. This approach can
also eliminate destructive interference that can be caused by directly folding
the address bits into half. \\
%
% djimenez: this is a nice intuition and explanation. 
% [EB] Thank you!
\textbf{Program Counter XOR Depth}: The PC is for the instruction that
triggered the prefetch chain. Depth refers to the iteration count of the
lookahead stages. In general, the PC is not considered as a good basis for
doing lookahead prefetching as all the prefetches with depth >= 1 are aliased
into the same PC which is not true in an actual demand access. This feature
resolves a PC into a different value for each lookahead depth of prefetch
speculation, giving a more accurate correlation in lookahead cases. This is
akin to the concept of Virtual Program Counters~\cite{VPC} introduced by Kim
\textit{et. al.} for indirect branch prediction. \\
%
\textbf{PC\textsubscript{1} XOR PC\textsubscript{2}>>1 XOR
PC\textsubscript{3}>>2}: Here $PC_i$ refers to the last $i^{th}$
PC before the instruction that triggered the current prefetch.
Hashing together the last three PCs tell PPF about the path that led
to the current demand access and helps capture and branching
information of the current basic block. PCs are shifted in the
increasing order of history before being hashed together. This is
done to avoid the resultant value of zero when 2 or more PCs are the
same. Additionally, blurring the information as it gets older
allows us to get a wider and approximate look into the program's
history. \\
%
\textbf{Program Counter XOR Delta}: This feature tells us if a given PC favors
particular value(s) of delta. As noted earlier, while the PC alone does not
convey useful information, this hash resolves the PC into different values
based on the tendency of that PC to favor a certain delta. Thus, the dynamic
nature of different instances of the same memory access instruction is
captured here. \\
%
 % GAC: Seems more predictable than dynamic if its capturing 
 % what is essentially a streaming access pattern. Not quite sure how to rephrase,
 % if I'm correct
%
 % GAC: Again having trouble phrasing the below point. I was attempting to say
 % that despite SPP having low confidence due to speculation, PPF may 
 % reinforce prefetches with lower confidence if SPP has had a tendency to be 
 % correct in the past.
\textbf{Confidence}: The integer confidence, on a scale of 0 to 100, that was
used in the original SPP design. While the original confidence does not
directly make the decision to prefetch, PPF correlates it to the correctness
of a proposed prefetch. While the original SPP may have dismissed a prefetch
due to running further into speculation, PPF can use the original confidence
as indicator of not only when prefetches become less confident, but also how
likely a low confident speculation is correct in the context of other
features. \\
\textbf{Page Address XOR Confidence}: This feature scores the tendency of each
page to be prefetch friendly or prefetch averse. It helps resolve a page into
different entries depending on its confidence for prefetching, which can vary
during phases of a program execution. \\
%
\textbf{Current Signature XOR Delta}: Recall from the discussion of SPP in
Section \ref{Background-SPP} that the new signature is generated using the old
signature and the current block delta. The result of this feature is the next
signature that is predicted to be accessed based on the delta predicted by
SPP. While ``Current Signature XOR Delta'' is not the exact formula for
generating the future signature, it gives an approximate idea of the path that
the combination of these two values can lead to. \\ \\
%
%Gino: Added the sentence below, is this correct?
%[EB]: It gives the next signature instead of next delta
%
%%%%%%% Below are the features rejected when downsizing 14 -> 9
% \item \textbf{Current Signature}: The 12-bit signature used by SPP
%   to index into the Pattern Table
% \item \textbf{Delta}: The signed version of the difference in the
%   block address that triggers the prefetch and the block address of
%   the data being prefetched
% \item \textbf{PC}: Program Counter of the Load instruction that
%   triggers that particular prefetch
% \item \textbf{Base address XOR Delta}: If any particular value(s) of
%   delta are highly favored by a given address which triggered the
%   prefetch, this composite feature can capture that information
% \item \textbf{Cache line XOR Delta}: this feature captures if any
%   particular delta is highly favored by a given cache line address
%\item \textbf{Confidence XOR Delta}: This gives a combined insight
%  into that fact that certain delta-confidence pairs predicted by
%  SPP might correlate more with the prefetch outcome
%%%%%%%%%%%%%%%%%%%%%%
%
Some of the composite features are derived from simple hashing (XOR)
of two primary features. There is always a question of usefulness of
such composite features and the new information added. We justify the
choice of each feature by quantifying the contribution made towards
predicting prefetch behavior, in Section \ref{Method-Features}.
Finally, as noted above, each feature indexes into its independent
entry of perceptron weights.

% [EB]: Think of more implementation specific details
% 7 to 12 bits of indexing
