\begin{abstract}

% djimenez: I have taken out parenthetical terms in favor of explicitly
% mentioning them in the text. some people have a visceral reaction against
% parentheses that delimit things essential to understanding the text.

Hardware prefetching is an effective technique for hiding cache miss latencies
in modern processor designs.  Prefetcher performance can be characterized by
two main metrics that are generally at odds with one another: coverage, {\em
i.e.} the improvement in cache misses; and accuracy, {\em i.e.} the fraction
of useful prefetches.  An overly aggressive prefetcher may improve coverage,
but may waste so many resources, {\em e.g.}, bandwidth, that performance is
harmed.  An ideal prefetcher would have both high coverage and accuracy.

%Hardware prefetching has been introduced in modern processors as a way to hide
%cache latencies.  An efficient prefetcher should identify complex
%memory access patterns during program execution. This ability enables the
%prefetcher to read a block ahead of its demand access, potentially preventing a
%cache miss. Accurately identifying the right blocks to prefetch is essential
%to achieving high performance from the prefetcher.

In this paper, we introduce Perceptron-based Prefetch Filtering (PPF) as a way
to reject inaccurate candidate prefetches generated by a baseline prefetcher.
PPF directly increases prefetcher accuracy and enables more aggressive tuning
of the baseline prefetcher, leading to increased coverage.  We also explore a
range of features to use to train PPF's perceptron layer.  PPF improves
performance on a memory-intensive subset of the SPEC CPU 2017 benchmarks by
6.84\% for a single-core configuration, and by 11.9\% for a 4-core
configuration, compared to the baseline prefetcher alone.  We also show that
performance continues to scale as the number of cores sharing a last level
cache increases.

%In this paper, we introduce Perceptron-based Prefetch Filtering to help make
% prefetching decisions accurately. The perceptron layer acts as a check 
%to filter out the unnecessary prefetches recommended by the underlying
%prefetcher.  We have also explored a range of features that can be used to
%train the perceptron layer.  Our results show that perceptron-based filtering
%improves performance on the memory intensive subset of the SPEC CPU 2017 benchmark
%suite by 6.84\% on single-core and by 11.9\% on multi-core traces, as compared
%to a state-of-the art prefetcher.  We also demonstrate that the performance
%gained from using our efficient filter continues to scale as the number of cores sharing a 
%last level cache increases.

\end{abstract}
